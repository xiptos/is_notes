{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/xiptos/is_notes/blob/main/gan.ipynb)\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"id\": \"5177223b0a951bd7\"\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"# Generative Adversarial Networks (GAN)\"\n",
    "   ],\n",
    "   \"metadata\": {},\n",
    "   \"id\": \"ae2d1db2-5877-4902-95cb-c70240edab78\"\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"5143fb0e-6409-4705-8a7a-3716cee44248\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Are based on a strategy where two different deep networks are pitted against one another, with the goal of getting **one network to create new samples** that are not from the training data, but are so much like the training data that the other **network canâ€™t tell the difference**.\\n\",\n",
    "    \"\\n\",\n",
    "    \"In this example, let's train a generator to produce gaussian distribution values based on random noise.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"f069a865-4db9-47c9-aad9-a10e6ff909b6\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Import libraries\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"c6116793-93b3-414c-95c3-cdeb99034fe7\",\n",
    "   \"metadata\": {\n",
    "    \"jupyter\": {\n",
    "     \"is_executing\": true\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"#importing Libraries\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.nn as nn\"\n",
    "   ],\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"7ac8af7e-273e-4abd-bbf4-e3e9ad55a532\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Understanding data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"124da025-8018-4a56-89b8-5d2f21895b13\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"from sklearn.datasets import make_blobs\\n\",\n",
    "    \"from scipy.stats import multivariate_normal\\n\",\n",
    "    \"\\n\",\n",
    "    \"X1, Y1 = make_blobs(n_samples=500, centers=[(5, 5)], n_features=3, random_state=0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig = plt.figure(figsize=(18, 8))\\n\",\n",
    "    \"\\n\",\n",
    "    \"#Parameters to set\\n\",\n",
    "    \"mu_x = 5\\n\",\n",
    "    \"variance_x = 0.5\\n\",\n",
    "    \"\\n\",\n",
    "    \"mu_y = 5\\n\",\n",
    "    \"variance_y = 0.5\\n\",\n",
    "    \"\\n\",\n",
    "    \"#Create grid and multivariate normal\\n\",\n",
    "    \"x = np.linspace(3, 7, 20)\\n\",\n",
    "    \"y = np.linspace(3, 7, 20)\\n\",\n",
    "    \"X, Y = np.meshgrid(x, y)\\n\",\n",
    "    \"pos = np.empty(X.shape + (2,))\\n\",\n",
    "    \"pos[:, :, 0] = X;\\n\",\n",
    "    \"pos[:, :, 1] = Y\\n\",\n",
    "    \"rv = multivariate_normal([mu_x, mu_y], [[variance_x, 0], [0, variance_y]])\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax1 = fig.add_subplot(1, 2, 1, projection='3d')\\n\",\n",
    "    \"surf = ax1.plot_surface(X, Y, rv.pdf(pos) * 3, rstride=1, cstride=1, linewidth=1, antialiased=False, cmap='viridis')\\n\",\n",
    "    \"ax2 = fig.add_subplot(1, 2, 2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax2.scatter(X1[:, 0], X1[:, 1], marker=\\\"o\\\", c=Y1, s=25, edgecolor=\\\"k\\\")\\n\",\n",
    "    \"cc = plt.Circle((5, 5), 1, fill=False, edgecolor='red', linewidth=2)\\n\",\n",
    "    \"ax2.set_aspect(1)\\n\",\n",
    "    \"ax2.add_artist(cc)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"48d029eb-7e09-40a4-9a32-2d8f0a432618\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(X1.shape)\\n\",\n",
    "    \"print(Y1.shape)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"9459b914-f9a7-495d-b693-d638dcd0bb8e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def generate_norm_data(batch_size: int = 16):\\n\",\n",
    "    \"    X1, Y1 = make_blobs(n_samples=batch_size, centers=[(5, 5)], n_features=3)\\n\",\n",
    "    \"    return X1\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"52b1dfd2-0ad9-4891-87e6-ba8cbad47787\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"from sklearn.datasets import make_blobs\\n\",\n",
    "    \"\\n\",\n",
    "    \"X1 = generate_norm_data(1000)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(8, 8))\\n\",\n",
    "    \"ax2 = plt.gca()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.title(\\\"One informative feature, one cluster per class\\\", fontsize=\\\"small\\\")\\n\",\n",
    "    \"ax2.scatter(X1[:, 0], X1[:, 1], marker=\\\"o\\\", s=25, edgecolor=\\\"k\\\")\\n\",\n",
    "    \"cc = plt.Circle((5, 5), 1, fill=False, edgecolor='red', linewidth=2)\\n\",\n",
    "    \"ax2.set_aspect(1)\\n\",\n",
    "    \"ax2.add_artist(cc)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"6653ab45-4081-4b0b-9566-3f43d12f5334\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from torch.utils.data import Dataset\\n\",\n",
    "    \"from torch.utils.data import DataLoader\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"class NormDataset(Dataset):\\n\",\n",
    "    \"    def __init__(self, n_samples=1000):\\n\",\n",
    "    \"        self.Xs, self.y = make_blobs(n_samples=n_samples, centers=[(5, 5)], n_features=3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __len__(self):\\n\",\n",
    "    \"        return len(self.Xs)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __getitem__(self, idx):\\n\",\n",
    "    \"        image = self.Xs[idx].astype(np.float32)\\n\",\n",
    "    \"        label = self.y[idx]\\n\",\n",
    "    \"        return image, label\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"0edc9144-be6d-417b-ab8c-d2c1c196015f\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## The generator\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"044ccc4e-fafd-4f7f-9a41-b58f8671e30b\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class Generator(nn.Module):\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        super().__init__()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        self.g = torch.nn.Sequential(\\n\",\n",
    "    \"            torch.nn.Linear(4, 16),\\n\",\n",
    "    \"            torch.nn.BatchNorm1d(16),\\n\",\n",
    "    \"            torch.nn.LeakyReLU(),\\n\",\n",
    "    \"            torch.nn.Linear(16, 2)\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def forward(self, x):\\n\",\n",
    "    \"        return self.g(x)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"6a8e19bc-2a4c-4e84-86b3-db7ef0d27093\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## The discriminator\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"076b1432-eaef-40a6-b4f1-0be1b26c92c6\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class Discriminator(nn.Module):\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        super().__init__()\\n\",\n",
    "    \"        self.d = torch.nn.Sequential(\\n\",\n",
    "    \"            torch.nn.Linear(2, 64),\\n\",\n",
    "    \"            torch.nn.LeakyReLU(),\\n\",\n",
    "    \"            torch.nn.Linear(64, 64),\\n\",\n",
    "    \"            torch.nn.LeakyReLU(),\\n\",\n",
    "    \"            torch.nn.Linear(64, 1),\\n\",\n",
    "    \"            torch.nn.Sigmoid()\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def forward(self, x):\\n\",\n",
    "    \"        res = self.d(x)\\n\",\n",
    "    \"        return res\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"66e2cd40-edd0-49b6-b5f8-f2b5040e97ef\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Training\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"3003b1ca-2aef-43ac-9dc4-1b214e186f9f\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"if torch.cuda.is_available():\\n\",\n",
    "    \"    device = torch.device(\\\"cuda\\\")\\n\",\n",
    "    \"elif torch.backends.mps.is_available():\\n\",\n",
    "    \"    device = torch.device(\\\"mps\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    device = torch.device(\\\"cpu\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Using device: {device}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"92e8109b-5eff-48e3-b158-e39c677133b2\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"epochs = 1000\\n\",\n",
    "    \"batch_size = 1000\\n\",\n",
    "    \"\\n\",\n",
    "    \"training_data = NormDataset(n_samples=10000)\\n\",\n",
    "    \"dataloader = DataLoader(training_data, batch_size=batch_size)\\n\",\n",
    "    \"\\n\",\n",
    "    \"G = Generator()\\n\",\n",
    "    \"D = Discriminator()\\n\",\n",
    "    \"D.to(device)\\n\",\n",
    "    \"G.to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Optimizers\\n\",\n",
    "    \"G_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\\n\",\n",
    "    \"D_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\\n\",\n",
    "    \"\\n\",\n",
    "    \"loss = nn.BCELoss()\\n\",\n",
    "    \"\\n\",\n",
    "    \"D_losses = []\\n\",\n",
    "    \"G_losses = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"test_data = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for epoch in range(epochs):\\n\",\n",
    "    \"    for idx, (true_data, _) in enumerate(dataloader):\\n\",\n",
    "    \"        # Training the discriminator\\n\",\n",
    "    \"        # Real inputs are actual examples with gaussian distribution\\n\",\n",
    "    \"        # Fake inputs are from the generator\\n\",\n",
    "    \"        # Real inputs should be classified as 1 and fake as 0\\n\",\n",
    "    \"        real_inputs = true_data.to(device)\\n\",\n",
    "    \"        real_outputs = D(real_inputs)\\n\",\n",
    "    \"        real_label = torch.ones(real_inputs.shape[0], 1).to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        noise = torch.tensor(np.random.normal(0, 1, (real_inputs.shape[0], 4))).float()\\n\",\n",
    "    \"        noise = noise.to(device)\\n\",\n",
    "    \"        fake_inputs = G(noise)\\n\",\n",
    "    \"        fake_outputs = D(fake_inputs)\\n\",\n",
    "    \"        fake_label = torch.zeros(fake_inputs.shape[0], 1).to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        outputs = torch.cat((real_outputs, fake_outputs), 0)\\n\",\n",
    "    \"        targets = torch.cat((real_label, fake_label), 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        D_loss = loss(outputs, targets)\\n\",\n",
    "    \"        D_optimizer.zero_grad()\\n\",\n",
    "    \"        D_loss.backward()\\n\",\n",
    "    \"        D_optimizer.step()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Training the generator\\n\",\n",
    "    \"        # For generator, goal is to make the discriminator believe everything is 1\\n\",\n",
    "    \"        noise = torch.tensor(np.random.normal(0, 1, (real_inputs.shape[0], 4))).float()\\n\",\n",
    "    \"        noise = noise.to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        fake_inputs = G(noise)\\n\",\n",
    "    \"        fake_outputs = D(fake_inputs)\\n\",\n",
    "    \"        fake_targets = torch.ones([fake_inputs.shape[0], 1]).to(device)\\n\",\n",
    "    \"        G_loss = loss(fake_outputs, fake_targets)\\n\",\n",
    "    \"        G_optimizer.zero_grad()\\n\",\n",
    "    \"        G_loss.backward()\\n\",\n",
    "    \"        G_optimizer.step()\\n\",\n",
    "    \"\\n\",\n",
    "    \"        G_losses.append(G_loss.item())\\n\",\n",
    "    \"        D_losses.append(D_loss.item())\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if (epoch + 1) % 100 == 0:\\n\",\n",
    "    \"        print('Epoch {} Iteration {}: discriminator_loss {:.3f} generator_loss {:.3f}'.format(epoch, idx, D_loss.item(), G_loss.item()))\\n\",\n",
    "    \"        test = (torch.rand(real_inputs.shape[0], 4) - 0.5) / 0.5\\n\",\n",
    "    \"        noise = torch.tensor(np.random.normal(0, 1, (real_inputs.shape[0], 4))).float().to(device)\\n\",\n",
    "    \"        test_data.append(G(noise).detach().cpu().numpy())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"a2ab7ebe-1641-49ff-a42b-607669215ad6\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Check training\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"f134be53-f5e9-4a66-80ea-150860db767a\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(len(test_data[0]))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"2874aab8-bd1a-4862-a1c2-0050a529c8f7\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#plot the loss function\\n\",\n",
    "    \"plt.plot(range(len(D_losses)), D_losses)\\n\",\n",
    "    \"plt.plot(range(len(G_losses)), G_losses)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.ylabel('Loss')\\n\",\n",
    "    \"plt.ylabel('batches')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"a17afd8f-8512-452c-9404-1b8364090eb6\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Evolution of the GAN training\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"11dfdcea-b987-4b14-a46d-9dcd2af9997b\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#noise = torch.randn(size=(500, 4)).cuda()\\n\",\n",
    "    \"#noise = (torch.rand(real_inputs.shape[0], 4) - 0.5) / 0.5\\n\",\n",
    "    \"#noise = torch.tensor(np.random.normal(0, 1, (500, 4))).float().cuda()\\n\",\n",
    "    \"#print(noise.shape)\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig = plt.figure(figsize=(18, 30))\\n\",\n",
    "    \"\\n\",\n",
    "    \"#generated_data = G(noise).detach().cpu().numpy()\\n\",\n",
    "    \"for i, generated_data in enumerate(test_data):\\n\",\n",
    "    \"    plt.subplot(8, 4, i + 1)\\n\",\n",
    "    \"    ax2 = plt.gca()\\n\",\n",
    "    \"\\n\",\n",
    "    \"    plt.title(\\\"Epoc %d\\\" % i, fontsize=\\\"small\\\")\\n\",\n",
    "    \"    ax2.scatter(generated_data[:, 0], generated_data[:, 1], marker=\\\"o\\\", s=25, edgecolor=\\\"k\\\")\\n\",\n",
    "    \"    cc = plt.Circle((5, 5), 1, fill=False, edgecolor='red', linewidth=2)\\n\",\n",
    "    \"    ax2.set_aspect(1)\\n\",\n",
    "    \"    ax2.add_artist(cc)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"outputs\": [],\n",
    "   \"source\": [],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   },\n",
    "   \"id\": \"dcbd199bcfb0d0e6\"\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "8626fbafb5632911"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
