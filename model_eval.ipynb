{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/xiptos/is_notes/blob/main/model_eval.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJR5_h1oiFMv"
   },
   "source": [
    "# Model Evaluation\n",
    "\n",
    "There are many ways to assess the predictive performance of a machine learning model. In this notebook, we discuss some evaluation metrics for classification and regression tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N6AXIl5Amb5K"
   },
   "source": [
    "# Evaluation Metrics for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rHgH9CjMmSu4"
   },
   "source": [
    "## Confusion matrix\n",
    "\n",
    "For classification tasks, several evaluation metrics can be computed from entries coming from a *confusion matrix*.\n",
    "\n",
    "A confusion matrix is ​​a tabular structure that presents a summary of the results produced by a classification model on a dataset.\n",
    "\n",
    "The image below shows schematically a confusion matrix for a binary classification model.\n",
    "\n",
    "![alt text](https://media.geeksforgeeks.org/wp-content/uploads/Confusion_Matrix1_1.png)\n",
    "\n",
    "The diagonal elements of a confusion matrix represent the number of instances for which the class predicted by the model is equal to the true class (aka *golden truth*). These are the true positives (TP) and true negatives (TN). The higher the diagonal values ​​of the confusion matrix, the better. The elements outside the diagonal are those that were classified incorrectly. These are the false negatives (FN) and false positives (FP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXBPxC1j4sA-"
   },
   "source": [
    "In Scikit-Learn, the function `confusion_matrix` produces a confusion matrix. This function expects to receive two arrays, one with the values ​​predicted by the classifier, and the other with the respective true values.\n",
    "\n",
    "The code cell below exemplifies the creation of confusion matrices for a classifier using the `confusion_matrix` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "8U6KuMpfm2ow",
    "outputId": "1ab33476-4b87-4f23-953f-45696cec7588"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/MLRG-CEFET-RJ/ml-class/master/datasets/pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pd.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "y = array[:,8]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "model = model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W31RCNhL5nFK"
   },
   "source": [
    "We can decorate the above output and generate an image for the confusion matrix by using the [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) function of the Seaborn package. See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "GmQlEtv55n3L",
    "outputId": "7b8784a8-a2d6-4005-97a3-64f83a1c96ed"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AycnifIlnaup"
   },
   "source": [
    "Confusion matrices are not restricted to binary classification problems. See the example below, which shows a graphical perspective of a confusion matrix resulting from a (ficticious) multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "S2avQwQrnbZA",
    "outputId": "149bea22-2188-4253-ba3d-725e4a5d6204"
   },
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "array = [[33,2,0,0,0,0,0,0,0,1,3], \n",
    "        [3,31,0,0,0,0,0,0,0,0,0], \n",
    "        [0,4,41,0,0,0,0,0,0,0,1], \n",
    "        [0,1,0,30,0,6,0,0,0,0,1], \n",
    "        [0,0,0,0,38,10,0,0,0,0,0], \n",
    "        [0,0,0,3,1,39,0,0,0,0,4], \n",
    "        [0,2,2,0,4,1,31,0,0,0,2],\n",
    "        [0,1,0,0,0,0,0,36,0,2,0], \n",
    "        [0,0,0,0,0,0,1,5,37,5,1], \n",
    "        [3,0,0,0,0,0,0,0,0,39,0], \n",
    "        [0,0,0,0,0,0,0,0,0,0,38]]\n",
    "df_cm = pd.DataFrame(array, index = [i for i in \"ABCDEFGHIJK\"],\n",
    "                  columns = [i for i in \"ABCDEFGHIJK\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3axOnMwgHxN"
   },
   "source": [
    "## Accuracy\n",
    "\n",
    "The formal definition of the accuracy measure is the following.\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "\n",
    "In Scikit-Learn, the function [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) procuces the accuracy measure for a given classification model. The following example illustrates the use of this function on the model previously fitted for the [Pima Indians dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Q4C95EFPp_Qr",
    "outputId": "ec65b8cf-f658-4854-b695-2cbebf099d4a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-oIN-FIBoLs3"
   },
   "source": [
    "## Precision, recall, $F_1$\n",
    "\n",
    "In addition to accuracy, there are other measures of predictive performance that can be calculated from the confusion matrix.\n",
    "\n",
    "* precision\n",
    "* recall\n",
    "* $F_1$ score\n",
    "\n",
    "To understand the measures listed above, suppose that each instance is of one of two classes, as sick and healthy. Call one class P (for \"positive\") and the other N (for \"negative\"). Consider building a model to classify future instances in classes P or N using a \"score\" associated with the values ​​of the target attribute. For example, like the results of laboratory tests. Another example: predict whether a person is a woman knowing how many shoes they have. When the score is high (greater than some borderline value, $t$), you classify the instance in class P; when the score is small (below the limit), you classify the instance as being of class N.\n",
    "\n",
    "Regardless of the value chosen for $t$, the model will incorrectly classify some instances (unless the data is completely separable). Suppose your male/female classification rule is \"predict that someone is female if they have more than 15 pairs of shoes\". For this rule, $t = 15$.\n",
    "\n",
    "* With this rule, the model will incorrectly classify any man who has more than 15 pairs of shoes. These individuals are false positives: the rule puts them in class P (female), but they do not belong to it.\n",
    "\n",
    "* However, the model will correctly classify women who have more than 15 pairs of shoes. These individuals are true positives: the rule puts them in class P, and that is where they belong.\n",
    "\n",
    "### Precision\n",
    "\n",
    "Precision is associated with the following question: \"When the model predicts that an instance is positive, how often is it correct?\". The expression to compute the precision of a classification model is presented below.\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "Precision is often the measure to optimize when the goal is to limit the number of false positives (FP) produced by the model. For example, in a spam message filtering program, this would possibly be the metric to be prioritized. That's because it is more critical to send a legitimate message to the spam box than to send a spam message to users' inbox.\n",
    "\n",
    "### Recall\n",
    "\n",
    "Recall is associated with the following question: \"When an instance is effectively positive, how often does the classifier correctly predict this?\". The expression to compute recall for a classification model is presented below.\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "Recall is generally used when the objective is to limit the number of false negatives (FN). For example, consider a medical exam used to detect an illness; it would be more appropriate to prioritize the building of models that maximize recall, since it is more critical to inform a patient with the disease that he does not have it.\n",
    "\n",
    "### $F_1$ score\n",
    "\n",
    "$F_1$ score is the [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean) between precision and recall. This metric should be used when both precision and recall need to be taken into account to produce a single evaluation value.\n",
    "\n",
    "$$\n",
    "F_1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "Being a harmonic mean, the $F_1$ measure penalizes models that present a great difference between values of precision and recall. Furthermore, this measure is prefered to accuracy in training scenarios involving unbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuNmjlDSpYSa"
   },
   "source": [
    "## `classification_report` function\n",
    "\n",
    "Scikit-learn provides the `classification_report` function, which produces a training evaluation report on a classification problem.\n",
    "\n",
    "The `classification_report` function displays values for accuracy, precision, recall, F1, and support for each class.\n",
    "\n",
    "The example below demonstrates the report produced for a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtqmD9X7Hn-H"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/MLRG-CEFET-RJ/ml-class/master/datasets/pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pd.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "y = array[:,8]\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_minmax = min_max_scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_minmax, y, train_size=.8)\n",
    "\n",
    "lr_model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "51SbqsN8W_b8",
    "outputId": "00b6307a-0f23-4754-a9a8-5bc74f19bccd"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "BLd7F8R4L6dw",
    "outputId": "b29b21b4-6825-4b9e-da84-09820fea7448"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QDvPDMD8KWaa"
   },
   "source": [
    "For comparison purposes, let us build another model, this time with a decision tree learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjw7cEx9Keub"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Rbm1HlEfLw40",
    "outputId": "749071a3-d68f-4046-dfb2-cd17421c60d1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vtco9MmgU6Co"
   },
   "source": [
    "## Area Under the Curve (AUC)\n",
    "\n",
    "Area under ROC Curve is a performance metric for measuring the ability of a binary classifier to discriminate between positive and negative classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "zkEI6IKhVFPs",
    "outputId": "d8cd2639-4cc9-4440-99ce-f223c82185da"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/MLRG-CEFET-RJ/ml-class/master/datasets/pima-indians-diabetes.csv\"\n",
    "dataframe = pandas.read_csv(url)\n",
    "dat = dataframe.values\n",
    "X = dat[:,:-1]\n",
    "y = dat[:,-1]\n",
    "seed = 7\n",
    "\n",
    "test_size = 0.3\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "                                                                    test_size=test_size, \n",
    "                                                                    random_state=seed)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC - Test Set: %.2f%%' % (auc*100))\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oV4HjaK3TH7d"
   },
   "source": [
    "# Evaluation Metrics for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUmE6OoNfLoX"
   },
   "source": [
    "As in the classification task, we can evaluate the predictive performance of a regression model. \n",
    "\n",
    "In the following discussion, consider that $\\hat{\\mathbf{y}}$ and $\\mathbf{y}$ are two $m$-dimensional vectors, $m$ being the amount of examples used for evalution. The $i$-th entries in $\\hat{\\mathbf{y}}$ and $\\mathbf{y}$ contain the predicted value and the effective value for the $i$-th sample, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAXn8_s2Ti69"
   },
   "source": [
    "## MSE, RMSE, MAE\n",
    "\n",
    "Three metrics are commonly used to evaluate regression models.\n",
    "\n",
    "* Mean Squared Error\n",
    "$$\n",
    "\\text{MSE}(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{1}{m}\\sum_{i=1}^{m}\\left[y^{(i)}-h_{\\Theta}(x^{(i)})\\right]^{2}\n",
    "$$\n",
    "\n",
    "* Root Mean Squared Error (the square root of MSE).\n",
    "$$\n",
    "\\text{RMSE}(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}\\left[y^{(i)}-h_{\\Theta}(x^{(i)})\\right]^{2}}\n",
    "$$\n",
    "\n",
    "* Mean Absolute Error\n",
    "\n",
    "$$\n",
    "\\text{MAE}(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{1}{m}\\sum_{i=1}^{m}\\left| y^{(i)}-h_{\\Theta}(x^{(i)}) \\right|\n",
    "$$\n",
    "\n",
    "In the expressions above:\n",
    "\n",
    "* $h_{\\Theta}$ represents the regression model learned by the algorithm, that is, $h_{\\Theta}(x^{(i)})$ is the predicted value for example $x^{(i)}$;\n",
    "* $m$ is the amount of examples; \n",
    "* $(x^{(i)}, y^{(i)})$ is the $i$-th example.\n",
    "\n",
    "Let us detail how the MSE measure is computed. For each of the $m$ training examples, the square of the difference between the value predicted by the model and the real value is computed first. Then, we add all these squared differences and divide by $m$ to obtain a single number. The final result is a statistic that represents the average distance between the model's predictions and the actual values. \n",
    "\n",
    "The following figure illustrates this calculation process. Suppose that the blue line is a regression model produced by some regression algorithm. In this case, $\\text{MSE}$  would produce a value that is a function of the distances of each example in the dataset (red dots) to the regressed line. These distances are depicted as green line segments. The average of the squred lengths of the green segments is the value of $\\text{MSE}$. \n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Linear_least_squares_example2.svg/220px-Linear_least_squares_example2.svg.png)\n",
    "\n",
    "In general, regression algorithms search for a setting of parameters that minimizes the value of one of the above measures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjxpcnLEfj8B"
   },
   "source": [
    "Scikit-Learn provides functions to compute each of the evaluation metrics above, as shown in the following example. This example uses the [Diabetes](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html) dataset, which comes with Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "-D0uObm2fsVK",
    "outputId": "130ede75-0e63-49fa-cbd0-4f6919e0a33a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/MLRG-CEFET-RJ/ml-class/master/datasets/pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "diabetes_df = pd.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "\n",
    "diabetes_X = array[:,0:8]\n",
    "diabetes_y = array[:,8]\n",
    "\n",
    "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = \\\n",
    "  train_test_split(diabetes_X, \n",
    "                   diabetes_y, \n",
    "                   train_size=.8, \n",
    "                   random_state=42)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "diabetes_X_train = min_max_scaler.fit_transform(diabetes_X_train)\n",
    "diabetes_X_test = min_max_scaler.transform(diabetes_X_test)\n",
    "\n",
    "# Create linear regression object (more about that later)\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training set\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "print('MSE: %.2f' % mean_squared_error(diabetes_y_test, y_pred))  \n",
    "print('RMSE: %.2f' % np.sqrt(mean_squared_error(diabetes_y_test, y_pred)))\n",
    "print('MAE: %.2f' % mean_absolute_error(diabetes_y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4zCCgCHUEl2"
   },
   "source": [
    "## R2 index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMgJGoOta-6p"
   },
   "source": [
    "The following example ([source](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py)) uses a single predictive feature of the [diabetes](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html) dataset to illustrate the application of OLS regression. In the example, a two-dimensional plot is displayed that shows how linear regression attempts to fit a straight line that minimizes the *residual sum of squares* between the responses observed in the dataset and the responses predicted by the linear approximation. The coefficients, the residual sum of the squares and the variance score are also calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "aDnQbq9zazqk",
    "outputId": "e4e5bca5-6655-414f-e47e-d54432083827"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# For simplicity's sake, use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "diabetes_y = diabetes.target\n",
    "\n",
    "diabetes_X_train, diabetes_X_test, diabetes_y_train, diabetes_y_test = \\\n",
    "  train_test_split(diabetes_X, \n",
    "                   diabetes_y, \n",
    "                   train_size=.8, \n",
    "                   random_state=42)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "diabetes_X_train = min_max_scaler.fit_transform(diabetes_X_train)\n",
    "diabetes_X_test = min_max_scaler.transform(diabetes_X_test)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training set\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients:', regr.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"MSE: %.2f\" % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('R2: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNTVAGIYe1nV"
   },
   "source": [
    "In the example above, also note the use of the `r2_score` function. In a regression task, the value returned by this function corresponds to the variance explained by the model: the value 1 corresponds to the perfect prediction. If the regression model naive, that is, it predicts $\\bar{y}$ for any example, then $R^2$ is equal to zero. The coefficient can also assume negative values, when the regression model has a worse quality than the naive regression model. This value is known as the coefficient of determination and is computed using the following equation:\n",
    "\n",
    "$$\n",
    "R^{2} = 1- \\frac{\\text{SS}_{\\text{res}}}{\\text{SS}_{\\text{tot}}}\n",
    "$$\n",
    "\n",
    "In the equation above, $\\text{SS}_{\\text{tot}}$ is the *total sum of squares*. This value is proportional to the variance of the components of $\\mathbf{y}$, the response vector. If $\\hat{y}$ is the average of the components of $\\mathbf{y}$, then $\\text{SS}_{\\text{tot}}$ is computed as below:\n",
    "\n",
    "$$\n",
    "\\text{SS}_{\\text{tot}} = \\sum_{i=1}^{m}\\left[y^{(i)}-{\\bar {y}}\\right]^{2}\n",
    "$$\n",
    "\n",
    "The value $\\text{SS}_{\\text{res}}$ corresponds to the *residual sum of squares*. $\\text{SS}_{\\text{res}}$ is computed as below:\n",
    "\n",
    "$$\n",
    "\\text{SS}_{\\text{res}} = \\sum_{i=1}^{m}\\left[y^{(i)}-h_\\Theta(x^{(i)})\\right]^{2}\n",
    "$$\n",
    "\n",
    "The following figure gives an intuition about the meaning of the $R^2$ score. The better the linear regression (on the right) fits the data compared to the simple average (in the graph on the left), the closer the value of $R^{2}$ will be. The areas of the blue squares ($\\text{SS}_{\\text{res}}$) represent the square residues in relation to the linear regression. The areas of the red squares ($\\text{SS}_{\\text{tot}}$) represent the square residues in relation to the average value.\n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Coefficient_of_Determination.svg/600px-Coefficient_of_Determination.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QtGgqLQgiWm_"
   },
   "source": [
    "The following code presents another example of using the `LinearRegression` class from Scikit-Learn, this time on the [California Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) dataset from Scikit-Learn. In this dataset, the target feature is the average residential price of houses of Boston districts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "CEhDbbbbWQm7",
    "outputId": "63d2e982-c8a2-45e3-ee05-c9d391f8778b"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "cal = fetch_california_housing()\n",
    "X = cal.data\n",
    "y = cal.target\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(X, y, train_size=.8, random_state=42)\n",
    "\n",
    "print('Dimensionality of the data matrix: ', X.shape)\n",
    "\n",
    "# Fit the regression model\n",
    "regr = LinearRegression()\n",
    "model = regr.fit(X_train, y_train)\n",
    "\n",
    "# Print the fist coefficient (intercept)\n",
    "print('Intercept: ', model.intercept_)\n",
    "\n",
    "# Print other coeficients\n",
    "print('Other coeficients:\\n', model.coef_)\n",
    "\n",
    "print('R2: %.2f' % model.score(X_test, y_test))\n",
    "\n",
    "# Apply the model on the first five test examples.\n",
    "print('Predictions for the first 5 observations in the test dataset:\\n', \n",
    "      list(model.predict(X_test)[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHgWP6l0e6z4"
   },
   "source": [
    "# Final Remaks\n",
    "\n",
    "Please notice that there many other evaluation metrics for supervised learning tasks. Some of them are: \n",
    "\n",
    "* True Positive Rate: proportion of positive samples that were correctly classified\n",
    "\n",
    "* False Positive Rate: the proportion of negative samples that were incorrectly classified\n",
    "\n",
    "* Likelihood\n",
    "\n",
    "* Posterior probability\n",
    "\n",
    "* Cost/utility\n",
    "\n",
    "* Margin\n",
    "\n",
    "* KL divergence\n",
    "\n",
    "Also notice that unsupervised learning task (e.g., clustering methods) have their own evaluation metrics.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPvFckdW3R+0cToPSgEFHmV",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ppcic-ml-modeleval-sup.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
