{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842ad9bf",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aede7eb2",
   "metadata": {},
   "source": [
    "Import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8062a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02cbf5",
   "metadata": {},
   "source": [
    "Utility functions, to store the temporary images and to convert matrix shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "    \n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e675634f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Transforms images to a PyTorch Tensor\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5,0.5)\n",
    "])\n",
    "\n",
    "# Download the MNIST Dataset\n",
    "dataset = datasets.MNIST(root = \"./data\", train = True,download = True,transform = img_transform)\n",
    "\n",
    "# DataLoader is used to load the dataset\n",
    "# for training\n",
    "loader = torch.utils.data.DataLoader(dataset = dataset,batch_size = batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a009910",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7582ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5ac348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PyTorch class\n",
    "# 28*28 ==> 9 ==> 28*28\n",
    "class AE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 784 ==> 9\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 2),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # The Sigmoid activation function\n",
    "        # outputs the value between 0 and 1\n",
    "        # 9 ==> 784\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 28 * 28),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded,decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model = AE()\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "\n",
    "# Validation using MSE Loss function\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate,weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37578072",
   "metadata": {},
   "source": [
    "## Training / Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6399f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"autoencoder_2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a124699",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(model_file):\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()\n",
    "else:\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in loader:\n",
    "            image, label = data\n",
    "\n",
    "            # Reshaping the image to (-1, 784)\n",
    "            image = image.view(image.size(0), -1)\n",
    "            #image = image.reshape(-1, 28*28)\n",
    "\n",
    "            # Output of Autoencoder\n",
    "            image = image.to(device)\n",
    "\n",
    "            _,reconstructed = model(image)\n",
    "\n",
    "            # Calculating the loss function\n",
    "            loss = loss_function(reconstructed, image)\n",
    "\n",
    "            # The gradients are set to zero,\n",
    "            # the the gradient is computed and stored.\n",
    "            # .step() performs parameter update\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Storing the losses in a list for plotting\n",
    "            losses.append(loss)\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data))\n",
    "        if epoch % 10 == 0:\n",
    "            pic = to_img(reconstructed.cpu().data)\n",
    "            save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    model.eval()\n",
    "    # Defining the Plot Style\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    # Plotting the last 100 values\n",
    "    plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d398439",
   "metadata": {},
   "source": [
    "## Display sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "fig = plt.figure(figsize=(20., 5.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 10),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    image,_ = dataset.__getitem__(random.randint(1,37000))\n",
    "\n",
    "    img = image.reshape(-1, 28*28)\n",
    "    _,reconstructed = model(img)\n",
    "    item = reconstructed.reshape(-1, 28, 28)\n",
    "    item = item.detach().numpy()\n",
    "\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    grid[i].imshow(image[0])\n",
    "    grid[i].grid(False)\n",
    "    grid[10+i].imshow(item[0])\n",
    "    grid[10+i].grid(False)\n",
    "\n",
    "\n",
    "plt.savefig(\"nums.png\",transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b21f2d",
   "metadata": {},
   "source": [
    "## Display latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a2b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "latents = []\n",
    "for i in range(10000):\n",
    "    sample_idx = torch.randint(len(dataset), size=(1,)).item()\n",
    "    img, label = dataset[sample_idx]\n",
    "    latent,output = model(img.reshape(-1,28*28))\n",
    "    latents.append(np.append(latent.detach().numpy(),label))\n",
    "\n",
    "latarray = np.stack(latents, axis=0 )\n",
    "df = pd.DataFrame(data=latarray, columns=(\"x1\", \"x2\", \"label\"))\n",
    "sns.FacetGrid(df, hue=\"label\", height=6).map(plt.scatter, 'x1', 'x2').add_legend()\n",
    "plt.savefig(\"latent_space.png\",transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_dict = {'label': int}\n",
    "df = df.astype(data_types_dict)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0eefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "#sns.despine(f, left=True, bottom=True)\n",
    "sns.scatterplot(x=\"x1\", y=\"x2\",\n",
    "                hue=\"label\",\n",
    "                legend=\"full\",\n",
    "                palette=\"tab10\",\n",
    "                linewidth=0,\n",
    "                data=df, ax=ax)\n",
    "plt.savefig(\"latent_space.png\",transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5152e88a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
