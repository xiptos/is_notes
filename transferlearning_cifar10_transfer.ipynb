{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/xiptos/is_notes/blob/main/cnn_transfer.ipynb)",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "In this example, we will use the CIFAR10 dataset, based on this [Pytorch Example](https://docs.pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). It has the classes: 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "# Training an image classifier\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalize the CIFAR10 training and test datasets using torchvision\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-11-20T11:59:55.135283Z",
     "iopub.execute_input": "2022-11-20T11:59:55.135779Z",
     "iopub.status.idle": "2022-11-20T11:59:57.228738Z",
     "shell.execute_reply.started": "2022-11-20T11:59:55.135682Z",
     "shell.execute_reply": "2022-11-20T11:59:57.227699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Set the device"
  },
  {
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-05T23:37:48.188818Z",
     "iopub.execute_input": "2022-08-05T23:37:48.18922Z",
     "iopub.status.idle": "2022-08-05T23:37:48.193684Z",
     "shell.execute_reply.started": "2022-08-05T23:37:48.18919Z",
     "shell.execute_reply": "2022-08-05T23:37:48.192628Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Load and normalize CIFAR10\n",
    "\n",
    "We obtain the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) via torchvision. The dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. Note that `datasets` is an object imported from torchvision, not to confuse with from the Dataset object (used in torch.utils.data import Dataset)\n",
    "\n",
    "```from torchvision import datasets```\n",
    "\n",
    "When called for the first time, the datasets will be downloaded to the path specified in the `root` argument. After that, Torchvision will look first for a local copy before attempting another download."
   ]
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-06T22:12:57.413031Z",
     "iopub.execute_input": "2022-08-06T22:12:57.413408Z",
     "iopub.status.idle": "2022-08-06T22:12:57.419602Z",
     "shell.execute_reply.started": "2022-08-06T22:12:57.413377Z",
     "shell.execute_reply": "2022-08-06T22:12:57.418347Z"
    }
   },
   "cell_type": "markdown",
   "source": "> **torchvision.transforms**. A transformer operates on the data. Using the 'transform' argument, we can apply multiple transformations (reshape, convert to tensor, normalize, etc.) to the data obtained. In this case, we are resizing the image to match the ImageNet dataset and normalizing according to the [ImageNet statistics](https://discuss.pytorch.org/t/discussion-why-normalise-according-to-imagenet-mean-and-std-dev-for-transfer-learning/115670)."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1) Transforms: resize 32x32 -> 224x224 + normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    # Use ImageNet normalization for pretrained weights\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": [
    "# DataLoader\n",
    "\n",
    "The PyTorch DataLoader object allows the preparation of the dataset in batches of different sizes and shuffles them if necessary when exposing them to the training.\n",
    "\n",
    "```from torch.utils.data import DataLoader```\n",
    "\n",
    "> Note that the DataLoader object shuffles the data by default."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## We have 10 classes, as follows"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "Let's use torchvision functionality to visualize a batch"
  },
  {
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-20T12:00:51.706437Z",
     "iopub.execute_input": "2022-11-20T12:00:51.70682Z",
     "iopub.status.idle": "2022-11-20T12:00:51.736293Z",
     "shell.execute_reply.started": "2022-11-20T12:00:51.706789Z",
     "shell.execute_reply": "2022-11-20T12:00:51.735106Z"
    },
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "Here we'll be using [AlexNet](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) architecture pretrained with [ImageNet](https://www.image-net.org/update-mar-11-2021.php)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "alexnet = alexnet.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-20T12:01:06.042304Z",
     "iopub.execute_input": "2022-11-20T12:01:06.042691Z",
     "iopub.status.idle": "2022-11-20T12:01:06.05135Z",
     "shell.execute_reply.started": "2022-11-20T12:01:06.042661Z",
     "shell.execute_reply": "2022-11-20T12:01:06.050039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Optionally freeze convolutional layers (feature extractor)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "for param in alexnet.features.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-20T12:01:10.616172Z",
     "iopub.execute_input": "2022-11-20T12:01:10.617368Z",
     "iopub.status.idle": "2022-11-20T12:01:10.622927Z",
     "shell.execute_reply.started": "2022-11-20T12:01:10.617323Z",
     "shell.execute_reply": "2022-11-20T12:01:10.621805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Replace the last classifier layer to output 10 classes (CIFAR-10)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_ftrs = alexnet.classifier[6].in_features\n",
    "alexnet.classifier[6] = nn.Linear(num_ftrs, 10)\n",
    "alexnet.classifier[6].requires_grad = True\n",
    "alexnet = alexnet.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Specify the loss function and optimizer"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, alexnet.parameters()), lr=1e-3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Training the network\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    alexnet.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    loop = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = alexnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update tqdm description\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    print(f\"Epoch {epoch+1} completed. Avg Loss = {epoch_loss:.4f}\\n\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-20T12:03:24.595312Z",
     "iopub.execute_input": "2022-11-20T12:03:24.596362Z",
     "iopub.status.idle": "2022-11-20T12:04:51.579405Z",
     "shell.execute_reply.started": "2022-11-20T12:03:24.596303Z",
     "shell.execute_reply": "2022-11-20T12:04:51.578093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Saving the model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "PATH = './transferlearning_cifar10_transfer.pth'\n",
    "torch.save(alexnet.state_dict(), PATH)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Test the network on the test data",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-06T02:24:07.967843Z",
     "iopub.execute_input": "2022-08-06T02:24:07.968441Z",
     "iopub.status.idle": "2022-08-06T02:24:07.972846Z",
     "shell.execute_reply.started": "2022-08-06T02:24:07.968408Z",
     "shell.execute_reply": "2022-08-06T02:24:07.971569Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll see train and test losses, together with its accuracies per epoch. Note that the training data have more minor losses and reach an accuracy of almost 100%. On the other hand, the test data reach almost a plateau of > 95% accuracy, and we could think of using more than two epochs because this is where the training data crosses the accuracy of the testing data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-20T12:19:02.347292Z",
     "iopub.execute_input": "2022-11-20T12:19:02.347668Z",
     "iopub.status.idle": "2022-11-20T12:19:02.694434Z",
     "shell.execute_reply.started": "2022-11-20T12:19:02.347638Z",
     "shell.execute_reply": "2022-11-20T12:19:02.693078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Next, let’s load back in our saved model (note: saving and re-loading the model wasn’t necessary here, we only did it to illustrate how to do so):",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-08T00:59:08.129764Z",
     "iopub.execute_input": "2022-08-08T00:59:08.130182Z",
     "iopub.status.idle": "2022-08-08T00:59:08.137731Z",
     "shell.execute_reply.started": "2022-08-08T00:59:08.130148Z",
     "shell.execute_reply": "2022-08-08T00:59:08.136336Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "PATH = './transferlearning_cifar10_transfer.pth'\n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = alexnet.classifier[6].in_features\n",
    "alexnet.classifier[6] = nn.Linear(num_ftrs, 10)\n",
    "alexnet.classifier[6].requires_grad = True\n",
    "\n",
    "state_dict = torch.load(PATH, map_location=\"cpu\")\n",
    "alexnet.load_state_dict(state_dict)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-20T12:19:10.729477Z",
     "iopub.execute_input": "2022-11-20T12:19:10.729899Z",
     "iopub.status.idle": "2022-11-20T12:19:11.901358Z",
     "shell.execute_reply.started": "2022-11-20T12:19:10.729859Z",
     "shell.execute_reply": "2022-11-20T12:19:11.900128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let us see what the neural network thinks these examples above are:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "outputs = alexnet(images)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-20T12:19:15.641037Z",
     "iopub.execute_input": "2022-11-20T12:19:15.641444Z",
     "iopub.status.idle": "2022-11-20T12:19:16.637063Z",
     "shell.execute_reply.started": "2022-11-20T12:19:15.641413Z",
     "shell.execute_reply": "2022-11-20T12:19:16.635805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions_l = predicted.tolist()\n",
    "labels_l = labels.tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let us look at how the network performs on the whole dataset."
  },
  {
   "cell_type": "code",
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = alexnet(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-20T12:19:19.35135Z",
     "iopub.execute_input": "2022-11-20T12:19:19.351999Z",
     "iopub.status.idle": "2022-11-20T12:19:19.802896Z",
     "shell.execute_reply.started": "2022-11-20T12:19:19.351962Z",
     "shell.execute_reply": "2022-11-20T12:19:19.801705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's breakdown the classes accuracy"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = alexnet(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Calculate and show the confusion matrix heatmap\n",
    "confusion_matrix = torch.zeros(len(classes), len(classes))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # images = images.to(device)  # Uncomment if running on GPU\n",
    "        # labels = labels.to(device)  # Uncomment if running on GPU\n",
    "        outputs = alexnet(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "            confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(confusion_matrix.numpy(), interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Add count annotations\n",
    "thresh = confusion_matrix.max() / 2.\n",
    "for i in range(confusion_matrix.shape[0]):\n",
    "    for j in range(confusion_matrix.shape[1]):\n",
    "        plt.text(j, i, int(confusion_matrix[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if confusion_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-20T12:19:22.262835Z",
     "iopub.execute_input": "2022-11-20T12:19:22.263252Z",
     "iopub.status.idle": "2022-11-20T12:19:23.045818Z",
     "shell.execute_reply.started": "2022-11-20T12:19:22.263218Z",
     "shell.execute_reply": "2022-11-20T12:19:23.04464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  }
 ]
}
