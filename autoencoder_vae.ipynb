{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5478df",
   "metadata": {},
   "source": [
    "# Variational Autoencoders (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4695249f",
   "metadata": {},
   "source": [
    "Import the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c0b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "from os.path import exists\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3957b76",
   "metadata": {},
   "source": [
    "Utility functions, to store the temporary images and to convert matrix shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6176f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./vae_img'):\n",
    "    os.mkdir('./vae_img')\n",
    "    \n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60991800",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa934d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Transforms images to a PyTorch Tensor\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download the MNIST Dataset\n",
    "dataset = datasets.MNIST(root = \"./data\", train = True,download = True,transform = img_transform)\n",
    "\n",
    "# DataLoader is used to load the dataset\n",
    "# for training\n",
    "loader = torch.utils.data.DataLoader(dataset = dataset,batch_size = batch_size,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead82fb",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5da8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(784, 400)\n",
    "        self.fc21 = torch.nn.Linear(400, 2)\n",
    "        self.fc22 = torch.nn.Linear(400, 2)\n",
    "        self.fc3 = torch.nn.Linear(2, 400)\n",
    "        self.fc4 = torch.nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cffd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Initialization\n",
    "model = VAE()\n",
    "#moving to gpu\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "reconstruction_function = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    BCE = reconstruction_function(recon_x, x)  # mse loss\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd4bad1",
   "metadata": {},
   "source": [
    "## Training / Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"vae.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0c694",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(model_file):\n",
    "    model.load_state_dict(torch.load(model_file))\n",
    "    model.eval()\n",
    "else:\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, data in enumerate(loader):\n",
    "            img, _ = data\n",
    "            img = img.view(img.size(0), -1)\n",
    "            img = Variable(img)\n",
    "            if torch.cuda.is_available():\n",
    "                img = img.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(img)\n",
    "            loss = loss_function(recon_batch, img, mu, logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.data\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch,\n",
    "                    batch_idx * len(img),\n",
    "                    len(loader.dataset), 100. * batch_idx / len(loader),\n",
    "                    loss.data / len(img)))\n",
    "\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(loader.dataset)))\n",
    "        if epoch % 10 == 0:\n",
    "            save = to_img(recon_batch.cpu().data)\n",
    "            save_image(save, './vae_img/image_{}.png'.format(epoch))\n",
    "\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "        \n",
    "    model.eval()\n",
    "    # Defining the Plot Style\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    # Plotting the last 100 values\n",
    "    plt.plot(losses[-100:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865dce98",
   "metadata": {},
   "source": [
    "## Display sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bceea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "model.eval()\n",
    "\n",
    "fig = plt.figure(figsize=(20., 5.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 10),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    image,_ = dataset.__getitem__(random.randint(1,37000))\n",
    "\n",
    "    img = image.reshape(-1, 28*28)\n",
    "    img = Variable(img)\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cuda()    \n",
    "\n",
    "    reconstructed, _, _ = model(img)\n",
    "    item = reconstructed.reshape(-1, 28, 28)\n",
    "    item = item.cpu().detach().numpy()\n",
    "\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    grid[i].imshow(image[0])\n",
    "    grid[i].grid(False)\n",
    "    grid[10+i].imshow(item[0])\n",
    "    grid[10+i].grid(False)\n",
    "\n",
    "\n",
    "plt.savefig(\"nums_vae.png\",transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d5a6f3",
   "metadata": {},
   "source": [
    "## Display latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ed62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "latents = []\n",
    "for i in range(10000):\n",
    "    sample_idx = torch.randint(len(dataset), size=(1,)).item()\n",
    "    img, label = dataset[sample_idx]\n",
    "    img = Variable(img)\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cuda()    \n",
    "\n",
    "    output,mu,logvar = model(img.reshape(-1,28*28))\n",
    "    latent = model.reparametrize(mu, logvar)\n",
    "\n",
    "    latents.append(np.append(latent.cpu().detach().numpy(),label))\n",
    "\n",
    "latarray = np.stack(latents, axis=0 )\n",
    "df = pd.DataFrame(data=latarray, columns=(\"x1\", \"x2\", \"label\"))\n",
    "sns.FacetGrid(df, hue=\"label\", height=6).map(plt.scatter, 'x1', 'x2').add_legend()\n",
    "plt.savefig(\"latent_space.png\",transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types_dict = {'label': int}\n",
    "df = df.astype(data_types_dict)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ed7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "#sns.despine(f, left=True, bottom=True)\n",
    "sns.scatterplot(x=\"x1\", y=\"x2\",\n",
    "                hue=\"label\",\n",
    "                legend=\"full\",\n",
    "                palette=\"tab10\",\n",
    "                linewidth=0,\n",
    "                data=df, ax=ax)\n",
    "plt.savefig(\"latent_space.png\",transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d439cbb7-9188-442a-b3e8-bec2dad210bf",
   "metadata": {},
   "source": [
    "## Testing on different space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e252699-c1e3-430a-a67b-7768a541c884",
   "metadata": {},
   "source": [
    "Visualize some MNIST samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb5607-d85c-4b87-9143-aa8df02fdf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "fig = plt.figure(figsize=(20., 5.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 10),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    image,_ = dataset.__getitem__(random.randint(1,37000))\n",
    "\n",
    "    img = image.reshape(-1, 28*28)\n",
    "    img = Variable(img)\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cuda()    \n",
    "\n",
    "    reconstructed, _, _ = model(img)\n",
    "    item = reconstructed.reshape(-1, 28, 28)\n",
    "    item = item.cpu().detach().numpy()\n",
    "\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    grid[i].imshow(image[0])\n",
    "    grid[i].grid(False)\n",
    "    grid[10+i].imshow(item[0])\n",
    "    grid[10+i].grid(False)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84ac20-4fd7-428f-8d1b-43e6f2626476",
   "metadata": {},
   "source": [
    "Download the FashionMNIST dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff13629-ad2d-4339-871c-e9daaf2243b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Fashion MNIST Dataset\n",
    "fashionDataset = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1451b14-6dcb-4c87-a7b3-917bd17ac25b",
   "metadata": {},
   "source": [
    "Visualize some Fashion MNIST samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70354ad5-d110-4afe-8f4c-5194a803ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
